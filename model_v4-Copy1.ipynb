{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Modèle complet : train avec toutes les données de toutes les parties de roues : \n",
    "     > ajours / galbe / central / crochet \n",
    "     > train successif de tous les modèlesn (sauver un modèle pour être sûr\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oui\n"
     ]
    }
   ],
   "source": [
    "print(\"oui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (2792,99)  # Images resize en taille ~ moyenne : moyenne pondérée\n",
    "INPUT_IMAGE_SHAPE = (99,2792,1) # shape qui rentre dans le cnn\n",
    "# même taille pour toutes les parties d'images, présentes en même densité\n",
    "\n",
    "THRESHOLD_PREDICTION = 0.5\n",
    "\n",
    "NUM_CALLS = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "DATA_PATH = \"/home/cogrannr/roues/MEFRO/grises/\"\n",
    "DATA_PATH_DEFAUTS_REELS = \"/home/cogrannr/roues/MEFRO/images_defauts/\"\n",
    "DATA_PATH_ROUES_ENTIERES=\"/home/cogrannr/roues/MEFRO/Images_Roues/Actuelle/gris_blanc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Fonction custom, car doit être fait en eager execution, sinon c'est un param \"none\" passé à Image.open\n",
    "    ouvereture des photos / resize\n",
    "\"\"\"\n",
    "def open_image(file_name): \n",
    "    name = tf.get_static_value(file_name)\n",
    "    name = name.decode()\n",
    "    \n",
    "    image = PIL.Image.open(name)\n",
    "    \n",
    "    image = image.resize(IMAGE_SIZE)\n",
    "    image_arr = np.array(image)\n",
    "    \n",
    "    image_arr = image_arr[:,:,np.newaxis]\n",
    "    return image_arr\n",
    "\n",
    "def open_image_entiere(file_name): \n",
    "    name = tf.get_static_value(file_name)\n",
    "    name = name.decode()\n",
    "    \n",
    "    image = PIL.Image.open(name)\n",
    "    \n",
    "    image = image.resize(IMAGE_SIZE)\n",
    "    image_arr = np.array(image)\n",
    "    return image_arr\n",
    "    \n",
    "def parse_images(filename,label): # appel \"open_image\"\n",
    "    image_arr = tf.py_function(open_image,[filename],tf.float32)\n",
    "    image_arr = tf.image.convert_image_dtype(image_arr,tf.float32)\n",
    "    return image_arr,label\n",
    "\n",
    "def parse_images_entieres(filename,label): # appel \"open_image\"\n",
    "    image_arr = tf.py_function(open_image_entiere,[filename],tf.float32)\n",
    "    image_arr = tf.image.convert_image_dtype(image_arr,tf.float32)\n",
    "    return image_arr,label\n",
    "\n",
    "def data_augmentation(image,label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    #image = tf.image.random_brightness(image, max_delta=10.0/255.0)\n",
    "    #image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    return image,label\n",
    "    \n",
    "def reset_shapes_gray(image,label):\n",
    "    image.set_shape(list(INPUT_IMAGE_SHAPE))\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    chargement des listes de fichiers photo\n",
    "\"\"\"\n",
    "def load_data(cover_dir,faulty_dir): \n",
    "    \n",
    "    file_names_cover = tf.data.Dataset.list_files(cover_dir+\"/*\",shuffle=False)\n",
    "    file_names_cover = file_names_cover.take(DATA_SIZE//2)\n",
    "    labels_0 = tf.data.Dataset.from_tensors(0).repeat()\n",
    "    data_set_cover = tf.data.Dataset.zip((file_names_cover,labels_0))\n",
    "    \n",
    "    file_names_faulty = tf.data.Dataset.list_files(faulty_dir+\"/*\",shuffle=False)\n",
    "    file_names_faulty = file_names_faulty.take(DATA_SIZE//2)\n",
    "    labels_1 = tf.data.Dataset.from_tensors(1).repeat()\n",
    "    data_set_faulty = tf.data.Dataset.zip((file_names_faulty,labels_1))\n",
    "   \n",
    "    data_set = data_set_cover.concatenate(data_set_faulty)\n",
    "    \n",
    "    tf.random.set_seed(1)\n",
    "    data_set = data_set.shuffle(DATA_SIZE)\n",
    "   \n",
    "    return data_set\n",
    "\n",
    "def load_data_entieres(cover_dir,faulty_dir, num_negative, num_positive): \n",
    "    \n",
    "    file_names_cover = tf.data.Dataset.list_files(cover_dir,shuffle=False)\n",
    "    labels_0 = tf.data.Dataset.from_tensors(0).repeat()\n",
    "    \n",
    "    data_set_cover = tf.data.Dataset.zip((file_names_cover,labels_0))\n",
    "    data_set_cover = data_set_cover.take(num_negative)\n",
    "    \n",
    "    \n",
    "    file_names_faulty = tf.data.Dataset.list_files(faulty_dir,shuffle=False)\n",
    "    labels_1 = tf.data.Dataset.from_tensors(1).repeat()\n",
    "    \n",
    "    data_set_faulty = tf.data.Dataset.zip((file_names_faulty,labels_1))\n",
    "    data_set_faulty = data_set_faulty.take(num_positive)\n",
    "    \n",
    "    data_set = data_set_cover.concatenate(data_set_faulty)\n",
    "    \n",
    "    tf.random.set_seed(1)\n",
    "    data_set = data_set.shuffle(DATA_SIZE)\n",
    "   \n",
    "    return data_set\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    répartition des fichiers enn ensembles train/valid\n",
    "\"\"\"\n",
    "def generate_train_valid_test(cover_dir,faulty_dir, augment_data=False, entieres=False,\n",
    "                             num_positive=0,num_negative=0): \n",
    "    \n",
    "    if entieres==True:\n",
    "        data_set = load_data_entieres(cover_dir, faulty_dir, num_negative,num_positive)\n",
    "    else:\n",
    "        data_set = load_data(cover_dir, faulty_dir)\n",
    "        \n",
    "    train_dataset = data_set.take(DATA_TRAIN_SIZE)\n",
    "    valid_dataset = data_set.skip(DATA_TRAIN_SIZE).take(DATA_VALID_SIZE)\n",
    "    test_dataset = data_set.skip(DATA_TRAIN_SIZE+DATA_VALID_SIZE).take(DATA_TEST_SIZE)\n",
    "\n",
    "    \n",
    "    datasets_list = []\n",
    "    \n",
    "    for data_set in [train_dataset, valid_dataset, test_dataset]:\n",
    "\n",
    "        if data_set == train_dataset:\n",
    "            if entieres == True:\n",
    "                data_set = data_set.map(parse_images_entieres, num_parallel_calls=NUM_CALLS)\n",
    "            else:\n",
    "                data_set = data_set.map(parse_images, num_parallel_calls=NUM_CALLS)\n",
    "            if augment_data == True:\n",
    "                data_set = data_set.map(reset_shapes_gray, num_parallel_calls=NUM_CALLS)\n",
    "                data_set = data_set.map(data_augmentation, num_parallel_calls=NUM_CALLS)\n",
    "        else:\n",
    "            if entieres == True:\n",
    "                data_set = data_set.map(parse_images_entieres, num_parallel_calls=NUM_CALLS)\n",
    "            else:\n",
    "                data_set = data_set.map(parse_images, num_parallel_calls=NUM_CALLS)\n",
    "            \n",
    "        data_set = data_set.map(reset_shapes_gray, num_parallel_calls=NUM_CALLS)\n",
    "            \n",
    "        data_set = data_set.batch(BATCH_SIZE)\n",
    "        data_set = data_set.prefetch(1)\n",
    "        \n",
    "        datasets_list.append(data_set)\n",
    "        \n",
    "    return datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix : \n",
    "\n",
    "def confusion_matrix(test_dataset,model, num_positive_class, num_negative_class):\n",
    "    \n",
    "    prediction = np.array([])\n",
    "    labels = tf.constant([], dtype=tf.int32)\n",
    "\n",
    "    for (data_batch, label_batch) in test_dataset:\n",
    "        prediction = np.concatenate((prediction, model.predict_on_batch(data_batch)[:,0]))\n",
    "        labels = tf.concat((labels, label_batch), axis=0)\n",
    "  \n",
    "    prediction[prediction > THRESHOLD_PREDICTION] = 1\n",
    "    prediction[prediction <= THRESHOLD_PREDICTION] = 0\n",
    "        \n",
    "    confusion_matrix = tf.math.confusion_matrix(\n",
    "        labels=labels,predictions=tf.convert_to_tensor(prediction),num_classes=2)\n",
    "\n",
    "    l = tf.get_static_value(labels)\n",
    "    \n",
    "    num_pos = np.sum(l==1)\n",
    "    num_neg = np.sum(l==0)\n",
    "    print(\"num pos \",num_pos)\n",
    "    print(\"num neg \",num_neg)\n",
    "    \n",
    "    nomralized_matrix = tf.get_static_value(confusion_matrix)\n",
    "    nomralized_matrix = nomralized_matrix.astype(np.float32)\n",
    "    \n",
    "    nomralized_matrix[0,:] = nomralized_matrix[0,:]/num_neg\n",
    "    nomralized_matrix[1,:] = nomralized_matrix[1,:]/num_pos\n",
    "\n",
    "    print(\"\\nConfusion matrix : \")\n",
    "    print(tf.get_static_value(confusion_matrix))\n",
    "    print(\"\\nNormalized confusion matrix : \")\n",
    "    print(nomralized_matrix)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(architecture=1):\n",
    "    \n",
    "    if architecture == 1:    # 1M param : MARCHE OK\n",
    "        model_input = tf.keras.Input(shape=INPUT_IMAGE_SHAPE)\n",
    "        conv_1 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='SAME',strides=(1,2))(model_input)\n",
    "        conv_2 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_1)\n",
    "        bn_1 = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "        mxp_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_1)\n",
    "        \n",
    "        conv_3 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='SAME',strides=(1,1))(mxp_1)\n",
    "        conv_4 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_3)\n",
    "        bn_2 = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "        mxp_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_2)\n",
    "        \n",
    "        conv_5 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='SAME',strides=(1,1))(mxp_2)\n",
    "        conv_6 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_5)\n",
    "        bn_3 = tf.keras.layers.BatchNormalization()(conv_6)\n",
    "        mxp_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_3)\n",
    "        \n",
    "        conv_7 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='SAME',strides=(1,1))(mxp_3)\n",
    "        conv_8 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='SAME',strides=(1,1))(conv_7)\n",
    "        bn_4 = tf.keras.layers.BatchNormalization()(conv_8)\n",
    "        mxp_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(bn_4)\n",
    "        \n",
    "        flat = tf.keras.layers.Flatten()(mxp_4)\n",
    "        drop = tf.keras.layers.Dropout(0.3)(flat)\n",
    "        out = tf.keras.layers.Dense(1,activation=\"sigmoid\")(drop)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=model_input, outputs=out)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dataset,valid_dataset, check_point_name, num_epochs,tensor_board_name=\"\"):\n",
    "    \n",
    "    precision_metric = tf.keras.metrics.Precision(thresholds=THRESHOLD_PREDICTION)\n",
    "    \n",
    "    call_backs_list = [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience = 2),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath =check_point_name, monitor =\"val_accuracy\", save_best_only = True),\n",
    "    ]\n",
    "    \n",
    "    if tensor_board_name != \"\":\n",
    "        board = tf.keras.callbacks.TensorBoard(log_dir='./tensor_board_'+tensor_board_name)\n",
    "        call_backs_list.append(board)\n",
    "   \n",
    "    optim = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "  \n",
    "    model.compile(loss='binary_crossentropy',optimizer=optim,\n",
    "        metrics=[precision_metric,\"accuracy\"]) \n",
    "    \n",
    "    model.fit(train_dataset,epochs=num_epochs,\n",
    "              validation_data=valid_dataset,\n",
    "             callbacks=call_backs_list\n",
    "             )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Images gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = int(146e3) # taille des données (test/valid/test compris), max : 146K\n",
    "DATA_TRAIN_SIZE = int(DATA_SIZE*0.6)\n",
    "DATA_VALID_SIZE = int(DATA_SIZE*0.2)\n",
    "DATA_TEST_SIZE = int(DATA_SIZE*0.2)\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.0001 \n",
    "\n",
    "NUM_EPOCHS = {\"galbe\":10, \"ajours\":10, \"crochet\":10, \"central\":150}\n",
    "\n",
    "SAVE_PATH = \"./\"\n",
    "\n",
    "NUM_POSITIVE_CLASS = DATA_TEST_SIZE//2\n",
    "NUM_NEGATIVE_CLASS = DATA_TEST_SIZE//2\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "MODEL_NAME = \"base_model_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 99, 2792, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 99, 1396, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 99, 1396, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 99, 1396, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 49, 698, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 49, 698, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 49, 698, 64)       36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 49, 698, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 349, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 349, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 349, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 24, 349, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 174, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 174, 256)      295168    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 12, 174, 256)      590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 12, 174, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 87, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 133632)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 133632)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 133633    \n",
      "=================================================================\n",
      "Total params: 1,307,233\n",
      "Trainable params: 1,306,273\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train for 5475 steps, validate for 1825 steps\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "5475/5475 [==============================] - 389s 71ms/step - loss: 0.3249 - precision_2: 0.8961 - accuracy: 0.8749 - val_loss: 0.2328 - val_precision_2: 0.9986 - val_accuracy: 0.9180\n",
      "Epoch 2/10\n",
      "5475/5475 [==============================] - 415s 76ms/step - loss: 0.1410 - precision_2: 0.9782 - accuracy: 0.9608 - val_loss: 0.3100 - val_precision_2: 0.9996 - val_accuracy: 0.9114\n",
      "Epoch 3/10\n",
      "5475/5475 [==============================] - 430s 79ms/step - loss: 0.1076 - precision_2: 0.9841 - accuracy: 0.9715 - val_loss: 1.7823 - val_precision_2: 0.5426 - val_accuracy: 0.5819\n",
      "Epoch 4/10\n",
      "5475/5475 [==============================] - 439s 80ms/step - loss: 0.1093 - precision_2: 0.9841 - accuracy: 0.9716 - val_loss: 0.1584 - val_precision_2: 0.9920 - val_accuracy: 0.9568\n",
      "Epoch 5/10\n",
      "5475/5475 [==============================] - 431s 79ms/step - loss: 0.1027 - precision_2: 0.9852 - accuracy: 0.9737 - val_loss: 0.0755 - val_precision_2: 0.9958 - val_accuracy: 0.9784\n",
      "Epoch 6/10\n",
      "5475/5475 [==============================] - 432s 79ms/step - loss: 0.0917 - precision_2: 0.9863 - accuracy: 0.9760 - val_loss: 0.0894 - val_precision_2: 0.9926 - val_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "5475/5475 [==============================] - 430s 79ms/step - loss: 0.0814 - precision_2: 0.9879 - accuracy: 0.9790 - val_loss: 0.0559 - val_precision_2: 0.9940 - val_accuracy: 0.9842\n",
      "Epoch 8/10\n",
      "4986/5475 [==========================>...] - ETA: 33s - loss: 0.0764 - precision_2: 0.9885 - accuracy: 0.9799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5475/5475 [==============================] - 434s 79ms/step - loss: 0.0785 - precision_2: 0.9883 - accuracy: 0.9795 - val_loss: 0.1046 - val_precision_2: 0.9909 - val_accuracy: 0.9674\n",
      "Epoch 10/10\n",
      "2251/5475 [===========>..................] - ETA: 3:35 - loss: 0.0713 - precision_2: 0.9895 - accuracy: 0.9801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    for wheel_part in [\"galbe\"]:# \"ajours\", \"crochet\", \"central\"]:\n",
    "        train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part, DATA_PATH+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "\n",
    "        model = init_model(architecture=1)\n",
    "        model = train_model(model, train_dataset, valid_dataset,\n",
    "                        check_point_name=SAVE_PATH+MODEL_NAME+wheel_part+\".h5\", num_epochs=NUM_EPOCHS[wheel_part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating resnet model for wheel part : galbe\n",
      "1825/1825 [==============================] - 62s 34ms/step - loss: 0.0579 - precision_2: 0.9937 - accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "# pour la RAM : bien shutdown le notebook avant cette partie !\n",
    "\n",
    "for wheel_part in [\"galbe\"]:#, \"ajours\", \"crochet\", \"central\"]:\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part, DATA_PATH+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "    \n",
    "    check_point = tf.keras.models.load_model(SAVE_PATH+MODEL_NAME+wheel_part+\".h5\")\n",
    "    \n",
    "    print(\"evaluating resnet model for wheel part : \"+wheel_part)\n",
    "    check_point.evaluate(test_dataset, verbose=1)\n",
    "    \n",
    "    #confusion_matrix(test_dataset, check_point, NUM_POSITIVE_CLASS, NUM_NEGATIVE_CLASS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8352, 11, 4)\n",
      "% of positives anchors >= 5, for every truth bbox : [0.86396928]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anchors\n",
    "\n",
    "\n",
    "INPUT_IMAGE_SHAPE = (99,2790,1)\n",
    "\n",
    "RATIO_X = 4\n",
    "RATIO_Y = 8\n",
    "\n",
    "anchor_sizes = ((10,20),\n",
    "            (20,40),\n",
    "            (35,70),\n",
    "            (50,100),\n",
    "            (10,10),\n",
    "            (15,15),\n",
    "            (20,20),\n",
    "            (25,25),\n",
    "            (30,30),\n",
    "            (40,40),\n",
    "            (50,50))\n",
    "\n",
    "\n",
    "bbox_list = np.genfromtxt(\"bbox_galbe_2.csv\",delimiter=\",\",dtype=np.int32)\n",
    "\n",
    "\n",
    "anchors_arr = anchors.generate(INPUT_IMAGE_SHAPE, RATIO_X, RATIO_Y, anchor_sizes)\n",
    "\n",
    "#positive_anchors_index, negative_anchors_index = compute_IoU(anchors,bbox_list[0],positive_threshold=0.6)\n",
    "\n",
    "#positive_anchors_index, negative_anchors_index = select_anchors(10,10,positive_anchors_index,negative_anchors_index)\n",
    "print(anchors_arr.shape)\n",
    "#draw_anchors(\"photo.pgm\",np.reshape(a,(-1,4)))\n",
    "anchors.debug_compute_number_positive_anchors(anchor_sizes,anchors_arr,\"bbox_galbe_2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 88.]\n",
      "   [ 85.]\n",
      "   [ 86.]\n",
      "   ...\n",
      "   [ 88.]\n",
      "   [ 88.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[ 94.]\n",
      "   [ 92.]\n",
      "   [ 91.]\n",
      "   ...\n",
      "   [ 91.]\n",
      "   [ 93.]\n",
      "   [ 94.]]\n",
      "\n",
      "  [[101.]\n",
      "   [ 99.]\n",
      "   [ 97.]\n",
      "   ...\n",
      "   [ 96.]\n",
      "   [ 99.]\n",
      "   [101.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[194.]\n",
      "   [196.]\n",
      "   [198.]\n",
      "   ...\n",
      "   [196.]\n",
      "   [194.]\n",
      "   [194.]]\n",
      "\n",
      "  [[194.]\n",
      "   [197.]\n",
      "   [200.]\n",
      "   ...\n",
      "   [195.]\n",
      "   [193.]\n",
      "   [194.]]\n",
      "\n",
      "  [[194.]\n",
      "   [197.]\n",
      "   [200.]\n",
      "   ...\n",
      "   [194.]\n",
      "   [193.]\n",
      "   [194.]]]\n",
      "\n",
      "\n",
      " [[[173.]\n",
      "   [174.]\n",
      "   [176.]\n",
      "   ...\n",
      "   [177.]\n",
      "   [175.]\n",
      "   [173.]]\n",
      "\n",
      "  [[179.]\n",
      "   [181.]\n",
      "   [185.]\n",
      "   ...\n",
      "   [188.]\n",
      "   [182.]\n",
      "   [178.]]\n",
      "\n",
      "  [[192.]\n",
      "   [195.]\n",
      "   [199.]\n",
      "   ...\n",
      "   [199.]\n",
      "   [195.]\n",
      "   [192.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 92.]\n",
      "   [ 95.]\n",
      "   [100.]\n",
      "   ...\n",
      "   [ 92.]\n",
      "   [ 92.]\n",
      "   [ 92.]]\n",
      "\n",
      "  [[138.]\n",
      "   [138.]\n",
      "   [138.]\n",
      "   ...\n",
      "   [137.]\n",
      "   [137.]\n",
      "   [137.]]\n",
      "\n",
      "  [[157.]\n",
      "   [157.]\n",
      "   [157.]\n",
      "   ...\n",
      "   [158.]\n",
      "   [157.]\n",
      "   [157.]]]\n",
      "\n",
      "\n",
      " [[[214.]\n",
      "   [212.]\n",
      "   [209.]\n",
      "   ...\n",
      "   [205.]\n",
      "   [211.]\n",
      "   [215.]]\n",
      "\n",
      "  [[213.]\n",
      "   [213.]\n",
      "   [213.]\n",
      "   ...\n",
      "   [214.]\n",
      "   [214.]\n",
      "   [213.]]\n",
      "\n",
      "  [[214.]\n",
      "   [211.]\n",
      "   [208.]\n",
      "   ...\n",
      "   [210.]\n",
      "   [212.]\n",
      "   [214.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[150.]\n",
      "   [151.]\n",
      "   [153.]\n",
      "   ...\n",
      "   [151.]\n",
      "   [150.]\n",
      "   [150.]]\n",
      "\n",
      "  [[163.]\n",
      "   [164.]\n",
      "   [165.]\n",
      "   ...\n",
      "   [161.]\n",
      "   [161.]\n",
      "   [161.]]\n",
      "\n",
      "  [[166.]\n",
      "   [166.]\n",
      "   [166.]\n",
      "   ...\n",
      "   [168.]\n",
      "   [167.]\n",
      "   [166.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 48.]\n",
      "   [ 47.]\n",
      "   [ 51.]\n",
      "   ...\n",
      "   [ 51.]\n",
      "   [ 49.]\n",
      "   [ 47.]]\n",
      "\n",
      "  [[ 55.]\n",
      "   [ 55.]\n",
      "   [ 58.]\n",
      "   ...\n",
      "   [ 55.]\n",
      "   [ 54.]\n",
      "   [ 55.]]\n",
      "\n",
      "  [[ 62.]\n",
      "   [ 62.]\n",
      "   [ 64.]\n",
      "   ...\n",
      "   [ 62.]\n",
      "   [ 59.]\n",
      "   [ 62.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73.]\n",
      "   [ 71.]\n",
      "   [ 71.]\n",
      "   ...\n",
      "   [ 72.]\n",
      "   [ 72.]\n",
      "   [ 73.]]\n",
      "\n",
      "  [[ 72.]\n",
      "   [ 74.]\n",
      "   [ 73.]\n",
      "   ...\n",
      "   [ 69.]\n",
      "   [ 71.]\n",
      "   [ 72.]]\n",
      "\n",
      "  [[ 71.]\n",
      "   [ 73.]\n",
      "   [ 72.]\n",
      "   ...\n",
      "   [ 69.]\n",
      "   [ 71.]\n",
      "   [ 71.]]]\n",
      "\n",
      "\n",
      " [[[ 61.]\n",
      "   [ 58.]\n",
      "   [ 58.]\n",
      "   ...\n",
      "   [ 58.]\n",
      "   [ 62.]\n",
      "   [ 59.]]\n",
      "\n",
      "  [[ 64.]\n",
      "   [ 63.]\n",
      "   [ 62.]\n",
      "   ...\n",
      "   [ 65.]\n",
      "   [ 66.]\n",
      "   [ 67.]]\n",
      "\n",
      "  [[ 67.]\n",
      "   [ 64.]\n",
      "   [ 64.]\n",
      "   ...\n",
      "   [ 69.]\n",
      "   [ 69.]\n",
      "   [ 67.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 82.]\n",
      "   [ 82.]\n",
      "   [ 84.]\n",
      "   ...\n",
      "   [ 81.]\n",
      "   [ 81.]\n",
      "   [ 81.]]\n",
      "\n",
      "  [[ 82.]\n",
      "   [ 81.]\n",
      "   [ 82.]\n",
      "   ...\n",
      "   [ 82.]\n",
      "   [ 83.]\n",
      "   [ 82.]]\n",
      "\n",
      "  [[ 85.]\n",
      "   [ 84.]\n",
      "   [ 84.]\n",
      "   ...\n",
      "   [ 84.]\n",
      "   [ 84.]\n",
      "   [ 85.]]]\n",
      "\n",
      "\n",
      " [[[ 67.]\n",
      "   [ 70.]\n",
      "   [ 68.]\n",
      "   ...\n",
      "   [ 69.]\n",
      "   [ 68.]\n",
      "   [ 68.]]\n",
      "\n",
      "  [[ 76.]\n",
      "   [ 75.]\n",
      "   [ 72.]\n",
      "   ...\n",
      "   [ 70.]\n",
      "   [ 69.]\n",
      "   [ 69.]]\n",
      "\n",
      "  [[ 80.]\n",
      "   [ 80.]\n",
      "   [ 79.]\n",
      "   ...\n",
      "   [ 74.]\n",
      "   [ 73.]\n",
      "   [ 74.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[166.]\n",
      "   [166.]\n",
      "   [166.]\n",
      "   ...\n",
      "   [173.]\n",
      "   [170.]\n",
      "   [166.]]\n",
      "\n",
      "  [[166.]\n",
      "   [167.]\n",
      "   [167.]\n",
      "   ...\n",
      "   [170.]\n",
      "   [168.]\n",
      "   [165.]]\n",
      "\n",
      "  [[168.]\n",
      "   [168.]\n",
      "   [169.]\n",
      "   ...\n",
      "   [167.]\n",
      "   [166.]\n",
      "   [166.]]]], shape=(16, 99, 2792, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for wheel_part in [\"galbe\"]:# \"ajours\", \"crochet\", \"central\"]:\n",
    "    train_dataset, valid_dataset, test_dataset = generate_train_valid_test(\n",
    "            DATA_PATH+\"img_\"+wheel_part, DATA_PATH+\"img_\"+wheel_part+\"_avec_defauts\")\n",
    "\n",
    "    for (x,y) in train_dataset:\n",
    "        break\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_derouetl",
   "language": "python",
   "name": "venv_derouetl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
